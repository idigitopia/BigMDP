{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 16:24:41,027:mylogger:creating directory:.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0228 16:24:41.027554 140426806925120 utils_directory.py:64] creating directory:.\n",
      "2020-02-28 16:24:41,030:mylogger:Creation of the directory . failed\n",
      "I0228 16:24:41.030246 140426806925120 utils_directory.py:26] Creation of the directory . failed\n",
      "2020-02-28 16:24:41,032:mylogger:creating directory:./result_dump\n",
      "I0228 16:24:41.032244 140426806925120 utils_directory.py:64] creating directory:./result_dump\n",
      "2020-02-28 16:24:41,034:mylogger:Creation of the directory ./result_dump failed\n",
      "I0228 16:24:41.034227 140426806925120 utils_directory.py:26] Creation of the directory ./result_dump failed\n",
      "2020-02-28 16:24:41,037:mylogger:creating directory:./result_dump/CartPole\n",
      "I0228 16:24:41.037255 140426806925120 utils_directory.py:64] creating directory:./result_dump/CartPole\n",
      "2020-02-28 16:24:41,039:mylogger:Creation of the directory ./result_dump/CartPole failed\n",
      "I0228 16:24:41.039665 140426806925120 utils_directory.py:26] Creation of the directory ./result_dump/CartPole failed\n",
      "2020-02-28 16:24:41,041:mylogger:creating directory:./result_dump/CartPole/CartPoleR1_bn-32_sym-1_rmax-False_strict_rmax-False_mult-5_bkp_f-100_device-GPU_priority-0\n",
      "I0228 16:24:41.041797 140426806925120 utils_directory.py:64] creating directory:./result_dump/CartPole/CartPoleR1_bn-32_sym-1_rmax-False_strict_rmax-False_mult-5_bkp_f-100_device-GPU_priority-0\n",
      "2020-02-28 16:24:41,043:mylogger:Creation of the directory ./result_dump/CartPole/CartPoleR1_bn-32_sym-1_rmax-False_strict_rmax-False_mult-5_bkp_f-100_device-GPU_priority-0 failed\n",
      "I0228 16:24:41.043938 140426806925120 utils_directory.py:26] Creation of the directory ./result_dump/CartPole/CartPoleR1_bn-32_sym-1_rmax-False_strict_rmax-False_mult-5_bkp_f-100_device-GPU_priority-0 failed\n",
      "2020-02-28 16:24:41,046:mylogger:creating directory:logs\n",
      "I0228 16:24:41.046411 140426806925120 utils_directory.py:64] creating directory:logs\n",
      "2020-02-28 16:24:41,052:mylogger:Creation of the directory logs failed\n",
      "I0228 16:24:41.052520 140426806925120 utils_directory.py:26] Creation of the directory logs failed\n",
      "2020-02-28 16:24:41,054:mylogger:creating directory:logs/py_logs\n",
      "I0228 16:24:41.054695 140426806925120 utils_directory.py:64] creating directory:logs/py_logs\n",
      "2020-02-28 16:24:41,057:mylogger:Creation of the directory logs/py_logs failed\n",
      "I0228 16:24:41.057155 140426806925120 utils_directory.py:26] Creation of the directory logs/py_logs failed\n",
      "2020-02-28 16:24:41,059:mylogger:creating directory:logs/py_logs/Symbolic\n",
      "I0228 16:24:41.059129 140426806925120 utils_directory.py:64] creating directory:logs/py_logs/Symbolic\n",
      "2020-02-28 16:24:41,062:mylogger:Creation of the directory logs/py_logs/Symbolic failed\n",
      "I0228 16:24:41.062990 140426806925120 utils_directory.py:26] Creation of the directory logs/py_logs/Symbolic failed\n",
      "2020-02-28 16:24:41,065:mylogger:creating directory:logs/py_logs/Symbolic/CartPole-Dec\n",
      "I0228 16:24:41.065997 140426806925120 utils_directory.py:64] creating directory:logs/py_logs/Symbolic/CartPole-Dec\n",
      "2020-02-28 16:24:41,071:mylogger:Creation of the directory logs/py_logs/Symbolic/CartPole-Dec failed\n",
      "I0228 16:24:41.071197 140426806925120 utils_directory.py:26] Creation of the directory logs/py_logs/Symbolic/CartPole-Dec failed\n",
      "2020-02-28 16:24:41,074:mylogger:creating directory:logs/py_logs/Symbolic/CartPole-Dec/_bn-32_sym-1_rmax-False_strict_rmax-False_mult-5_bkp_f-100_device-GPU_priority-0\n",
      "I0228 16:24:41.074536 140426806925120 utils_directory.py:64] creating directory:logs/py_logs/Symbolic/CartPole-Dec/_bn-32_sym-1_rmax-False_strict_rmax-False_mult-5_bkp_f-100_device-GPU_priority-0\n",
      "2020-02-28 16:24:41,077:mylogger:Creation of the directory logs/py_logs/Symbolic/CartPole-Dec/_bn-32_sym-1_rmax-False_strict_rmax-False_mult-5_bkp_f-100_device-GPU_priority-0 failed\n",
      "I0228 16:24:41.077421 140426806925120 utils_directory.py:26] Creation of the directory logs/py_logs/Symbolic/CartPole-Dec/_bn-32_sym-1_rmax-False_strict_rmax-False_mult-5_bkp_f-100_device-GPU_priority-0 failed\n",
      "2020-02-28 16:24:41,079:mylogger:creating directory:logs/py_logs/Symbolic/CartPole-Dec/_bn-32_sym-1_rmax-False_strict_rmax-False_mult-5_bkp_f-100_device-GPU_priority-0/_default_time\n",
      "I0228 16:24:41.079224 140426806925120 utils_directory.py:64] creating directory:logs/py_logs/Symbolic/CartPole-Dec/_bn-32_sym-1_rmax-False_strict_rmax-False_mult-5_bkp_f-100_device-GPU_priority-0/_default_time\n",
      "2020-02-28 16:24:41,083:mylogger:Creation of the directory logs/py_logs/Symbolic/CartPole-Dec/_bn-32_sym-1_rmax-False_strict_rmax-False_mult-5_bkp_f-100_device-GPU_priority-0/_default_time failed\n",
      "I0228 16:24:41.083772 140426806925120 utils_directory.py:26] Creation of the directory logs/py_logs/Symbolic/CartPole-Dec/_bn-32_sym-1_rmax-False_strict_rmax-False_mult-5_bkp_f-100_device-GPU_priority-0/_default_time failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Environment  Loaded\n",
      "20000 20000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 16:24:41,860:mylogger:Average Reward of collected trajectories:22.273\n",
      "2020-02-28 16:24:41,860:mylogger:Average Reward of collected trajectories:22.273\n",
      "I0228 16:24:41.860825 140426806925120 dataset.py:292] Average Reward of collected trajectories:22.273\n",
      "2020-02-28 16:24:41,965:mylogger:Average Reward of collected trajectories:20.686\n",
      "2020-02-28 16:24:41,965:mylogger:Average Reward of collected trajectories:20.686\n",
      "I0228 16:24:41.965205 140426806925120 dataset.py:292] Average Reward of collected trajectories:20.686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward of collected trajectories:22.273\n",
      "Average Reward of collected trajectories:20.686\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import argparse\n",
    "from copy import deepcopy as cpy\n",
    "\n",
    "# from async_vi.MDP import *\n",
    "import numpy as np\n",
    "from bigmdp.data.dataset import SimpleReplayBuffer, PrioritizedReplayBuffer\n",
    "from bigmdp.data.env_gym import SimpleNormalizeEnv\n",
    "from bigmdp.mdp.MDP_GPU import FullMDP\n",
    "from bigmdp.utils.image_wrappers import *\n",
    "from bigmdp.utils.tmp_vi_helper import *\n",
    "from bigmdp.utils.utils_directory import *\n",
    "from bigmdp.utils.utils_log import *\n",
    "from hyper_params import HYPERPARAMS\n",
    "from bigmdp.data.dataset import gather_data_in_buffer\n",
    "\n",
    "# Get all Arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--bottle_neck_size\", help=\"size\", type=int, default=32)\n",
    "parser.add_argument(\"--discrete_bn\", help=\"size\", type=int, default=0)\n",
    "parser.add_argument(\"--multiplyer\", help=\"multiplyer of feature space\", type=int, default=10)\n",
    "parser.add_argument(\"--env\", help=\"environment name\", type=str, default=\"CartPole\")\n",
    "parser.add_argument(\"--name\", help=\"Experiment name\", type=str, default=\"CartPoleR1\")\n",
    "parser.add_argument(\"--load\", help=\"Load the previous MDP ?\", type=int, default=0)\n",
    "parser.add_argument(\"--symbolic\", help=\"Use Symbolic env if 1 else use image based env\", type=int, default=1)\n",
    "parser.add_argument(\"--steps_to_train\", help=\"Number of steps to train the whole pipeline\", type=int, default=0)\n",
    "parser.add_argument(\"--rmax\", help=\"Use rmax exploration?\", type=int, default=0)\n",
    "parser.add_argument(\"--strict_rmax\", help=\"Use rmax exploration and rmax exploration alone?\", type=int, default=0)\n",
    "parser.add_argument(\"--video_every\", help=\"get a rollout video every\", type=int, default=999999999)\n",
    "parser.add_argument(\"--backup_every\", help=\"do a bellman backup every k frames\", type=int, default=10)\n",
    "parser.add_argument(\"--device\", help=\"do backups on ?\", type=str, default=\"GPU\")\n",
    "parser.add_argument(\"--save_transitions\", help=\"do backups on ?\", type=int, default=0)\n",
    "parser.add_argument(\"--shaped_reward\", help=\"Use shaped rewards?\", type=int, default=0)\n",
    "parser.add_argument(\"--load_time_string\", help=\"timestep string\", type=str, default=\"default_time\")\n",
    "parser.add_argument(\"--use_priority_buffer\", help=\"Use priority buffer ?\", type=int, default=0)\n",
    "parser.add_argument(\"--render_every\", help=\"render a episode every kth episode\", type=int, default=0)\n",
    "parser.add_argument(\"--internal_count_override\", help=\"override internal count\", type=int, default=0)\n",
    "\n",
    "\n",
    "# args = parser.parse_args()\n",
    "args = parser.parse_args(\"--env CartPole --multiplyer 5 --rmax 0 --backup_every 100 --render_every 10000\".split(\" \"))\n",
    "\n",
    "run_params = \"_bn-\" + str(args.bottle_neck_size) + \\\n",
    "             \"_sym-\" + str(args.symbolic) + \\\n",
    "             \"_rmax-\" + str(bool(args.rmax)) + \\\n",
    "             \"_strict_rmax-\" + str(bool(args.strict_rmax)) + \\\n",
    "             \"_mult-\" + str(args.multiplyer) + \\\n",
    "             \"_bkp_f-\" + str(args.backup_every) + \\\n",
    "             \"_device-\" + str(args.device) + \\\n",
    "             \"_priority-\" + str(args.use_priority_buffer)\n",
    "\n",
    "base_file_path = \"./result_dump/{}/{}\".format(args.env, args.name + run_params)\n",
    "\n",
    "create_hierarchy(base_file_path)\n",
    "\n",
    "train_epochs = 20\n",
    "\n",
    "log_dirs_dict, loggers_dict = get_advanced_log_dir_and_logger(ROOT_FOLDER=\"Symbolic\" if args.symbolic else \"Image\",\n",
    "                                                              EXP_ID=args.env + \"-Dec\", #todo remove for general\n",
    "                                                              EXP_PARAMS=run_params,\n",
    "                                                              load_time_string=args.load_time_string,\n",
    "                                                              tb_log_keys=[\"tb_train_logger\", \"tb_valid_logger\"])\n",
    "\n",
    "if args.symbolic:\n",
    "    params = HYPERPARAMS[args.env + \"-sym\"]\n",
    "    if os.path.exists(\"./\" + str(args.env) + \"_env.pk\"):\n",
    "        print(\" Environment  Loaded\")\n",
    "        env = torch.load(\"./\" + str(args.env) + \"_env.pk\")\n",
    "    else:\n",
    "        env = SimpleNormalizeEnv(params[\"env_name\"], max_episode_length=params[\"max_episode_length\"])\n",
    "        torch.save(env, \"./\" + str(args.env) + \"_env.pk\")\n",
    "else:\n",
    "    print(\"Not Implemented Yet\")  # Todo\n",
    "    params = HYPERPARAMS[args.env + \"-img\"]\n",
    "    assert False\n",
    "\n",
    "test_env = cpy(env)\n",
    "\n",
    "\n",
    "K_s, K_i = params[\"replay_initial\"], args.internal_count_override if args.internal_count_override else params[\n",
    "    'internal_step_count_per_policy']\n",
    "print(K_i, K_s)\n",
    "\n",
    "if args.load:\n",
    "    mdp = torch.load(base_file_path + \"mdp_class.pth\")\n",
    "else:\n",
    "    mdp = FullMDP(A=env.get_list_of_actions(),\n",
    "                  ur=params[\"unknown_transition_reward\"],\n",
    "                  vi_params={\"gamma\": params[\"gamma\"],\n",
    "                             \"slip_prob\": params[\"slip_probability\"],\n",
    "                             \"rmax_reward\": params[\"rmax_reward\"],\n",
    "                             \"rmax_thres\": 2,\n",
    "                             \"balanced_explr\": True,\n",
    "                             \"rmin\": params[\"rmin\"]},\n",
    "                  policy_params={\"unhash_array_len\": env._env.observation_space.shape[0]},\n",
    "                  MAX_S_COUNT=int(1e5),\n",
    "                  weight_transitions=False,\n",
    "                  default_mode = args.device)\n",
    "\n",
    "all_rewards = []\n",
    "eval_rewards, safe_eval_rewards = [], []\n",
    "policy_fetch_time = []\n",
    "bellman_backup_time = [9999]\n",
    "train_buffer = PrioritizedReplayBuffer(int(5e5)) if args.use_priority_buffer else SimpleReplayBuffer(int(5e5))\n",
    "valid_buffer = PrioritizedReplayBuffer(int(1e5)) if args.use_priority_buffer else SimpleReplayBuffer(int(5e5))\n",
    "\n",
    "eps_tracker = EpsilonTracker(params)\n",
    "\n",
    "frame_count = 0\n",
    "warmup_eps = 10\n",
    "eval_reward = 0\n",
    "\n",
    "omit_list = [\"end_state\", \"unknown_state\"]\n",
    "\n",
    "\n",
    "# Collect random Dataset # till replay initial\\\n",
    "random_policy = lambda s: env.sample_random_action()\n",
    "train_buffer, info = gather_data_in_buffer(train_buffer, env, episodes=9999, render=False, policy=random_policy,\n",
    "                                           frame_count=K_s, pad_attribute_fxn={\"qval\": lambda s: 0})\n",
    "valid_buffer, info = gather_data_in_buffer(valid_buffer, env, episodes=9999, render=False, policy=random_policy,\n",
    "                                           frame_count=int(K_s / 5), pad_attribute_fxn={\"qval\": lambda s: 0})\n",
    "\n",
    "# recon_loss_wts = {h:0 for h in training_net.head_ids}\n",
    "# recon_loss_wts[\"recon\"] = 1\n",
    "# training_net.default_loss_wts  = recon_loss_wts\n",
    "# training_net.fit(train_buffer,valid_buffer, epochs=50)\n",
    "frame_count = 0\n",
    "print(frame_count)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "args.model_update_every = 500\n",
    "\n",
    "outer_loop_frame_count = len(train_buffer)\n",
    "\n",
    "    # torch.save((train_buffer.buffer, mdp, net.state_dict()), log_dirs_dict[\"py_log_dir\"] + \"/checkpoint\" + \".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params[\"evaluate_every\"] = 5000\n",
    "params[\"outer_iteration_count\"] = 1\n",
    "params[\"bellman_backup_every\"] = 100\n",
    "params[\"n_backups\"] = 10\n",
    "K_i = int(2e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_2_disc_fxn(s):\n",
    "    if len(s)==1:\n",
    "        return s[0] * args.multiplyer\n",
    "    else:\n",
    "        return [s_ * args.multiplyer for s_ in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:04<00:00, 16.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of MDP, 547\n",
      "Time takedn to solve 2.4566853046417236\n"
     ]
    }
   ],
   "source": [
    "\n",
    "outer_count = 0 \n",
    "# Update the buffer with new values\n",
    "# For Disc: Skipped\n",
    "\n",
    "# Train your Network\n",
    "# For Disc: Skipped\n",
    "\n",
    "#Make MDP\n",
    "mdp_T = FullMDP(A=env.get_list_of_actions(),\n",
    "              ur=params[\"unknown_transition_reward\"],\n",
    "              vi_params={\"gamma\": params[\"gamma\"],\n",
    "                         \"slip_prob\": params[\"slip_probability\"],\n",
    "                         \"rmax_reward\": params[\"rmax_reward\"],\n",
    "                         \"rmax_thres\": 2,\n",
    "                         \"balanced_explr\": True,\n",
    "                         \"rmin\": params[\"rmin\"]},\n",
    "              policy_params={\"unhash_array_len\": env._env.observation_space.shape[0]},\n",
    "              MAX_S_COUNT=int(1e6),\n",
    "              weight_transitions=True,\n",
    "              default_mode=\"GPU\")\n",
    "\n",
    "# Populate your MDP\n",
    "mdp_T = populate_model_from_buffer(mdp_T, train_buffer, img_2_disc_fxn)\n",
    "print(\"Size of MDP,\", len(mdp_T.tD))\n",
    "\n",
    "# Solve Your MDP\n",
    "mdp_T.solve(eps=1, mode=args.device)\n",
    "\n",
    "# for mdp_name, M in {\"Tabular\": mdp_T, \"Tabular_Insertion\": mdp_TI}.items():\n",
    "\n",
    "opt_policy = lambda s: mdp_T.get_opt_action(hAsh(img_2_disc_fxn([s]).tolist()), mode = args.device)\n",
    "safe_policy = lambda s: mdp_T.get_safe_action(hAsh(img_2_disc_fxn([s]).tolist()), mode = args.device)\n",
    "explr_policy = lambda s: mdp_T.get_explr_action(hAsh(img_2_disc_fxn([s]).tolist()), mode = args.device)\n",
    "random_policy = lambda s: env.sample_random_action()\n",
    "eps_opt_policy = get_eps_policy(opt_policy, random_policy, epsilon=0.2)\n",
    "\n",
    "if args.strict_rmax:\n",
    "    explore_policies = {\"explr_policy\": explr_policy}\n",
    "elif args.rmax:\n",
    "    explore_policies = {\"explr_policy\": explr_policy, \"opt_policy\": opt_policy}\n",
    "else:\n",
    "    explore_policies = {\"opt_policy\": opt_policy, \"eps_opt_policy\":eps_opt_policy}\n",
    "\n",
    "s = env.reset()\n",
    "running_reward = 0\n",
    "inner_loop_frame_count = 0\n",
    "eps_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.render_every = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5030/100000000 [00:30<2797:23:49,  9.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "151.14         | 703         | 352/1406              | 0.2504     | 0.4210205078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8499/100000000 [00:43<101:45:40, 272.95it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-68ae2fb95282>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mouter_loop_frame_count\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bellman_backup_every'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mmdp_T\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_optimal_backup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_backups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"n_backups\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mmdp_T\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_explr_backup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_backups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"n_backups\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/guille/afern/users/shrestaa/library_projects/EMDP/bigmdp/mdp/MDP_GPU.py\u001b[0m in \u001b[0;36mdo_optimal_backup\u001b[0;34m(self, mode, n_backups)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt_bellman_backup_step_cpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"GPU\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_mdp_from_cpu_to_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_backups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt_bellman_backup_step_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/guille/afern/users/shrestaa/library_projects/EMDP/bigmdp/mdp/MDP_GPU.py\u001b[0m in \u001b[0;36msync_mdp_from_cpu_to_gpu\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msync_mdp_from_cpu_to_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranCountMatrix_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpuarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranCountMatrix_cpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranProbMatrix_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpuarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranProbMatrix_cpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranidxMatrix_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpuarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranidxMatrix_cpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewardMatrix_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpuarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewardMatrix_cpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/guille/afern/users/shrestaa/installation_files/MinicondaInstallation/envs/pytorch_env/lib/python3.6/site-packages/pycuda/gpuarray.py\u001b[0m in \u001b[0;36mto_gpu\u001b[0;34m(ary, allocator)\u001b[0m\n\u001b[1;32m   1048\u001b[0m     \u001b[0;34m\"\"\"converts a numpy array to a GPUArray\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPUArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallocator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_compact_strides\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/guille/afern/users/shrestaa/installation_files/MinicondaInstallation/envs/pytorch_env/lib/python3.6/site-packages/pycuda/gpuarray.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, ary, async_, stream, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m             \u001b[0m_memcpy_discontig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masync_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/guille/afern/users/shrestaa/installation_files/MinicondaInstallation/envs/pytorch_env/lib/python3.6/site-packages/pycuda/gpuarray.py\u001b[0m in \u001b[0;36m_memcpy_discontig\u001b[0;34m(dst, src, async_, stream)\u001b[0m\n\u001b[1;32m   1313\u001b[0m                 \u001b[0mdrv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemcpy_htod_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpudata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1315\u001b[0;31m                 \u001b[0mdrv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemcpy_htod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpudata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1316\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for i in tqdm(range(int(1e8))):\n",
    "    inner_loop_frame_count += 1\n",
    "    outer_loop_frame_count += 1\n",
    "\n",
    "    if args.render_every and eps_count % args.render_every == 0:\n",
    "        env.render()\n",
    "\n",
    "    if outer_loop_frame_count % params['bellman_backup_every'] == 0:\n",
    "        st = time.time()\n",
    "        mdp_T.do_optimal_backup(mode=args.device, n_backups=params[\"n_backups\"])\n",
    "        if args.rmax:\n",
    "            mdp_T.do_explr_backup(mode=args.device, n_backups=params[\"n_backups\"])\n",
    "        bellman_backup_time.append(time.time() - st)\n",
    "\n",
    "    policy_name, policy = \"a\", eps_opt_policy # list(explore_policies.items())[eps_count%len(explore_policies)]\n",
    "    a = policy(s)\n",
    "\n",
    "    ns, r, d, i = env.step(a)\n",
    "    _d = False if d and i[\"max_episode_length_exceeded\"] == True else d\n",
    "    running_reward += r\n",
    "\n",
    "    # add to buffer\n",
    "    # Not necessary for Decimal Discretization bur sure\n",
    "    exp = [s.tolist(), [a], ns.tolist(), [r], [_d]]\n",
    "    train_buffer.add(exp, padded_info={\"qval\": 0})\n",
    "    if np.random.randint(20) < 2:\n",
    "        valid_buffer.add(exp, padded_info={\"qval\": 0})\n",
    "\n",
    "    # Update MDP\n",
    "    s_d, ns_d = img_2_disc_fxn([s]), img_2_disc_fxn([ns])\n",
    "    hs_d, hns_d = hAsh(s_d.tolist()), hAsh(ns_d.tolist())\n",
    "    mdp_T.consume_transition([hs_d, int(a), hns_d, float(r), int(_d)])\n",
    "#     mdp_T.consume_transition((hAsh(hs.tolist()), int(a), hAsh(hns.tolist()), float(r), int(_d)))\n",
    "\n",
    "    # prep for next loop\n",
    "    s = ns\n",
    "\n",
    "    # Housekeeping to omit while true loop\n",
    "    if d:\n",
    "        s = env.reset()\n",
    "        running_reward = 0\n",
    "        eps_count += 1\n",
    "\n",
    "    if inner_loop_frame_count % params['evaluate_every'] == 0:\n",
    "        mdp_T.do_optimal_backup(mode=\"GPU\", n_backups=500)\n",
    "        n_steps = outer_count * K_i + inner_loop_frame_count\n",
    "        eval_reward = evaluate_on_env(test_env, opt_policy, eps_count=50, render=False)[0]\n",
    "        \n",
    "        col_header = [\"Average Reward\",\"MDP #States\", \"#MissingTrans/ #Trans\",\"Missing %\", \"VI Error\"] \n",
    "        meta_data = [10]*len(col_header) # max len of the data in the table to be printed (per column)\n",
    "        print(' | '.join([s.ljust(max(meta_data[i], len(s)), '.') for i, s in enumerate(col_header)]))\n",
    "        col_data = [eval_reward, \n",
    "                    len(mdp_T.tD),  \n",
    "                    str(mdp_T.missing_state_action_count)+\"/\"+str(len(mdp_T.tD)*len(mdp_T.A)),\n",
    "                    round(mdp_T.missing_state_action_count/mdp_T.total_state_action_count,4 ),\n",
    "                    mdp_T.curr_vi_error       ]\n",
    "        print(' | '.join([str(s).ljust(max(meta_data[i], len(col_header[i])),  \" \") for i, s in enumerate(col_data)]))\n",
    "        \n",
    "        loggers_dict[\"tb_train_logger\"].add_scalar(\"Optimal Avg Reward\", n_steps)\n",
    "        loggers_dict[\"tb_train_logger\"].add_scalar(\"State Count\", float(len(mdp_T.tD)), outer_loop_frame_count)\n",
    "        loggers_dict[\"tb_train_logger\"].add_scalar('Mising Transition Count', mdp.missing_state_action_count, outer_loop_frame_count)\n",
    "        loggers_dict[\"tb_train_logger\"].add_scalar(\"Opt VI Error\",mdp_T.curr_vi_error, outer_loop_frame_count)\n",
    "        loggers_dict[\"tb_train_logger\"].add_scalar(\"Safe VI Error\",mdp_T.s_curr_vi_error, outer_loop_frame_count)\n",
    "\n",
    "    ####################################################\n",
    "\n",
    "    # Not necessary for Decimal Experiments\n",
    "    # if outer_loop_frame_count % args.checkpoint_every == 0:\n",
    "    #     training_net._save_to_cache()\n",
    "    #     torch.save((train_buffer.buffer, mdp, net.state_dict()),\n",
    "    #                log_dirs_dict[\"py_log_dir\"] + \"/checkpoint\" + \".pth\")\n",
    "\n",
    "# Not necessary for Decimal Experiments\n",
    "# training_net._save_to_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
