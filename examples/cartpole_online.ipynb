{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tips to run in Colab\n",
    "# set the runtime to a GPU instance. (runtime > change runtime type > GPU)\n",
    "# Uncomment following lines to set up dependencies in Colab Server\n",
    "\n",
    "# ! pip install pycuda\n",
    "# ! git clone https://github.com/idigitopia/BigMDP.git \n",
    "# import os\n",
    "# os.chdir(\"BigMDP\")\n",
    "# ! pip install -e . \n",
    "# os.chdir(\"examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# import plotly.graph_objects as go\n",
    "from tqdm import tqdm\n",
    "from gym import envs\n",
    "import argparse\n",
    "import numpy as np\n",
    "from bigmdp.data.buffer import StandardBuffer,ReplayBuffer, gather_data_in_buffer, get_iter_indexes\n",
    "from bigmdp.mdp.MDP_GPU import FullMDP\n",
    "from bigmdp.utils.utils_eval import evaluate_on_env\n",
    "from bigmdp.mdp.agent import SimpleAgent\n",
    "from copy import deepcopy as cpy\n",
    "from os import path\n",
    "from arg_def import * \n",
    "import gym\n",
    "from sklearn.neighbors import KDTree\n",
    "from IPython import display\n",
    "import torch\n",
    "import time\n",
    "import copy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################    envArgs    ##################################################\n",
      "env_name                       : CartPole-v0                    seed                           : 4444\n",
      "###################################################################################################################\n",
      "##################################################    mdpBuildArgs    ##################################################\n",
      "unknown_transition_reward      : -1000                          rmax_reward                    : 10000\n",
      "balanced_exploration           : 0                              rmax_threshold                 : 2\n",
      "MAX_S_COUNT                    : 100000                         def_device                     : GPU\n",
      "fill_with                      : 0Q_src-KNN                     mdp_build_k                    : 5\n",
      "knn_delta                      : 1e-08                          penalty_type                   : linear\n",
      "penalty_beta                   : 1                              filter_with_abstraction        : 0\n",
      "normalize_by_distance          : True                          \n",
      "########################################################################################################################\n",
      "##################################################    mdpSolveArgs    ##################################################\n",
      "gamma                          : 0.99                           slip_probability               : 0.1\n",
      "target_vi_error                : 0.001                          bellman_backup_every           : 100\n",
      "n_backups                      : 10                             policy_k                       : [11]\n",
      "########################################################################################################################\n",
      "##################################################    evalArgs    ##################################################\n",
      "eval_episode_count             : 249                            soft_q                         : False\n",
      "smooth_with_seen               : False                          policy_k                       : [11]\n",
      "####################################################################################################################\n"
     ]
    }
   ],
   "source": [
    "parser, ArgumentDict = get_argument_parser()\n",
    "options = \"--env_name CartPole-v0 --MAX_S_COUNT 100000 --MAX_NS_COUNT 5 --mdp_build_k 5 --policy_k 11 --normalize_by_distance\"\n",
    "args = parser.parse_args(options.split(\" \"))\n",
    "\n",
    "for title, arg_names in ArgumentDict.items():\n",
    "    print_args(args, to_show_args=arg_names, title = title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(args.env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_buffer = ReplayBuffer(state_dim = env.observation_space.shape[0],\n",
    "                           is_atari= False, \n",
    "                           atari_preprocessing= None, \n",
    "                           batch_size=32, \n",
    "                           buffer_size=20000,\n",
    "                           device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyNet():\n",
    "    def __init__(self, sim, add_noise=False):\n",
    "        self.simulator = sim\n",
    "\n",
    "    def encode_single(self, o):\n",
    "        return tuple(o)\n",
    "\n",
    "    def encode_batch(self, o_batch):\n",
    "        return [tuple(o) for o in o_batch]\n",
    "\n",
    "    def predict_single_transition(self, o, a):\n",
    "        assert False, \"Not Implemented Error\"\n",
    "\n",
    "    def predict_batch_transition(self, o_batch, a_batch):\n",
    "        assert False, \"Not Implemented Error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_MDP = FullMDP(A= list(range(env.action_space.n)),\n",
    "                ur=args.unknown_transition_reward,\n",
    "                vi_params={\"gamma\":  args.gamma,\n",
    "                           \"slip_prob\": args.slip_probability,\n",
    "                           \"rmax_reward\": args.rmax_reward,\n",
    "                           \"rmax_thres\": args.rmax_threshold,\n",
    "                           \"balanced_explr\": args.balanced_exploration,\n",
    "                          \"rmin\":-1000},\n",
    "                knn_delta=args.knn_delta,\n",
    "                MAX_S_COUNT=args.MAX_S_COUNT,\n",
    "                MAX_NS_COUNT=args.MAX_NS_COUNT,\n",
    "                default_mode=args.def_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "newAgent =  SimpleAgent(mdp_T= cpy(empty_MDP), net = DummyNet(None), fill_with = args.fill_with,\n",
    "                       mdp_build_k = args.mdp_build_k, plcy_k = args.policy_k[0],  \n",
    "                       kNN_on_sa = args.smooth_with_seen, soft_at_plcy = args.soft_q, \n",
    "                       normalize_by_distance= args.normalize_by_distance,\n",
    "                       penalty_type=args.penalty_type, penalty_beta = args.penalty_beta,abstraction_flag=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward of collected trajectories:21.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 47.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 5, Size of MDP:108, Length of Train Buffer:105, Eval Reward:68.72\t####################\n",
      "Average Reward of collected trajectories:81.0\n",
      "Average Reward of collected trajectories:68.2\n",
      "Average Reward of collected trajectories:60.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 40.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 20, Size of MDP:1156, Length of Train Buffer:301, Eval Reward:78.36\t####################\n",
      "Average Reward of collected trajectories:83.6\n",
      "Average Reward of collected trajectories:96.6\n",
      "Average Reward of collected trajectories:103.4\n",
      "Average Reward of collected trajectories:135.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 19.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 40, Size of MDP:3254, Length of Train Buffer:678, Eval Reward:172.52\t####################\n",
      "Average Reward of collected trajectories:155.0\n",
      "Average Reward of collected trajectories:156.2\n",
      "Average Reward of collected trajectories:158.2\n",
      "Average Reward of collected trajectories:132.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 19.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 60, Size of MDP:6266, Length of Train Buffer:661, Eval Reward:164.96\t####################\n",
      "Average Reward of collected trajectories:138.8\n",
      "Average Reward of collected trajectories:152.0\n",
      "Average Reward of collected trajectories:184.4\n",
      "Average Reward of collected trajectories:173.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 17.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 80, Size of MDP:9515, Length of Train Buffer:866, Eval Reward:183.14\t####################\n",
      "Average Reward of collected trajectories:172.0\n",
      "Average Reward of collected trajectories:169.4\n",
      "Average Reward of collected trajectories:178.4\n",
      "Average Reward of collected trajectories:185.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 16.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 100, Size of MDP:13048, Length of Train Buffer:927, Eval Reward:188.6\t####################\n",
      "Average Reward of collected trajectories:183.0\n",
      "Average Reward of collected trajectories:188.8\n",
      "Average Reward of collected trajectories:155.6\n",
      "Average Reward of collected trajectories:181.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 17.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 120, Size of MDP:16601, Length of Train Buffer:906, Eval Reward:187.68\t####################\n",
      "Average Reward of collected trajectories:176.2\n",
      "Average Reward of collected trajectories:148.6\n",
      "Average Reward of collected trajectories:181.6\n",
      "Average Reward of collected trajectories:156.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 16.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 140, Size of MDP:19919, Length of Train Buffer:781, Eval Reward:190.5\t####################\n",
      "Average Reward of collected trajectories:194.6\n",
      "Average Reward of collected trajectories:186.6\n",
      "Average Reward of collected trajectories:181.2\n",
      "Average Reward of collected trajectories:165.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 16.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 160, Size of MDP:23565, Length of Train Buffer:824, Eval Reward:192.38\t####################\n",
      "Average Reward of collected trajectories:170.6\n",
      "Average Reward of collected trajectories:187.2\n",
      "Average Reward of collected trajectories:196.4\n",
      "Average Reward of collected trajectories:192.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 16.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 180, Size of MDP:27306, Length of Train Buffer:960, Eval Reward:189.52\t####################\n",
      "Average Reward of collected trajectories:195.0\n",
      "Average Reward of collected trajectories:174.6\n",
      "Average Reward of collected trajectories:181.8\n",
      "Average Reward of collected trajectories:185.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 16.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 200, Size of MDP:30999, Length of Train Buffer:927, Eval Reward:197.04\t####################\n",
      "Average Reward of collected trajectories:200.0\n",
      "Average Reward of collected trajectories:195.6\n",
      "Average Reward of collected trajectories:198.8\n",
      "Average Reward of collected trajectories:198.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 16.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 220, Size of MDP:34978, Length of Train Buffer:993, Eval Reward:196.38\t####################\n",
      "Average Reward of collected trajectories:175.0\n",
      "Average Reward of collected trajectories:160.6\n",
      "Average Reward of collected trajectories:200.0\n",
      "Average Reward of collected trajectories:169.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 16.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 240, Size of MDP:38513, Length of Train Buffer:844, Eval Reward:197.44\t####################\n",
      "Average Reward of collected trajectories:194.8\n",
      "Average Reward of collected trajectories:191.2\n",
      "Average Reward of collected trajectories:200.0\n",
      "Average Reward of collected trajectories:193.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 16.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 260, Size of MDP:42424, Length of Train Buffer:967, Eval Reward:197.68\t####################\n",
      "Average Reward of collected trajectories:196.8\n",
      "Average Reward of collected trajectories:200.0\n",
      "Average Reward of collected trajectories:185.0\n",
      "Average Reward of collected trajectories:198.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:04<00:00, 11.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 280, Size of MDP:46336, Length of Train Buffer:989, Eval Reward:198.28\t####################\n",
      "Average Reward of collected trajectories:163.6\n",
      "Average Reward of collected trajectories:192.0\n",
      "Average Reward of collected trajectories:194.4\n",
      "Average Reward of collected trajectories:197.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 15.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 300, Size of MDP:50087, Length of Train Buffer:986, Eval Reward:198.48\t####################\n",
      "Average Reward of collected trajectories:20.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 65.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 5, Size of MDP:105, Length of Train Buffer:102, Eval Reward:48.58\t####################\n",
      "Average Reward of collected trajectories:45.2\n",
      "Average Reward of collected trajectories:38.6\n",
      "Average Reward of collected trajectories:145.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 22.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 20, Size of MDP:1250, Length of Train Buffer:725, Eval Reward:139.48\t####################\n",
      "Average Reward of collected trajectories:101.4\n",
      "Average Reward of collected trajectories:110.0\n",
      "Average Reward of collected trajectories:104.4\n",
      "Average Reward of collected trajectories:150.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 16.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 40, Size of MDP:3582, Length of Train Buffer:751, Eval Reward:184.38\t####################\n",
      "Average Reward of collected trajectories:173.6\n",
      "Average Reward of collected trajectories:199.4\n",
      "Average Reward of collected trajectories:197.6\n",
      "Average Reward of collected trajectories:164.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 15.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 60, Size of MDP:7265, Length of Train Buffer:820, Eval Reward:200.0\t####################\n",
      "Average Reward of collected trajectories:172.4\n",
      "Average Reward of collected trajectories:187.4\n",
      "Average Reward of collected trajectories:200.0\n",
      "Average Reward of collected trajectories:198.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 15.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 80, Size of MDP:11069, Length of Train Buffer:991, Eval Reward:197.28\t####################\n",
      "Average Reward of collected trajectories:179.2\n",
      "Average Reward of collected trajectories:190.6\n",
      "Average Reward of collected trajectories:181.6\n",
      "Average Reward of collected trajectories:200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 15.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 100, Size of MDP:14838, Length of Train Buffer:999, Eval Reward:199.98\t####################\n",
      "Average Reward of collected trajectories:196.6\n",
      "Average Reward of collected trajectories:199.2\n",
      "Average Reward of collected trajectories:184.0\n",
      "Average Reward of collected trajectories:188.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 15.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 120, Size of MDP:18693, Length of Train Buffer:943, Eval Reward:194.46\t####################\n",
      "Average Reward of collected trajectories:184.6\n",
      "Average Reward of collected trajectories:191.8\n",
      "Average Reward of collected trajectories:200.0\n",
      "Average Reward of collected trajectories:200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 15.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 140, Size of MDP:22589, Length of Train Buffer:999, Eval Reward:197.98\t####################\n",
      "Average Reward of collected trajectories:188.0\n",
      "Average Reward of collected trajectories:200.0\n",
      "Average Reward of collected trajectories:195.8\n",
      "Average Reward of collected trajectories:188.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 15.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 160, Size of MDP:26463, Length of Train Buffer:942, Eval Reward:199.86\t####################\n",
      "Average Reward of collected trajectories:200.0\n",
      "Average Reward of collected trajectories:200.0\n",
      "Average Reward of collected trajectories:200.0\n",
      "Average Reward of collected trajectories:200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 15.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 180, Size of MDP:30479, Length of Train Buffer:999, Eval Reward:199.88\t####################\n",
      "Average Reward of collected trajectories:185.8\n",
      "Average Reward of collected trajectories:200.0\n",
      "Average Reward of collected trajectories:198.2\n",
      "Average Reward of collected trajectories:200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 15.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 200, Size of MDP:34412, Length of Train Buffer:999, Eval Reward:200.0\t####################\n",
      "Average Reward of collected trajectories:188.2\n",
      "Average Reward of collected trajectories:188.6\n",
      "Average Reward of collected trajectories:200.0\n",
      "Average Reward of collected trajectories:194.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 14.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 220, Size of MDP:38278, Length of Train Buffer:969, Eval Reward:200.0\t####################\n",
      "Average Reward of collected trajectories:200.0\n",
      "Average Reward of collected trajectories:188.6\n",
      "Average Reward of collected trajectories:200.0\n",
      "Average Reward of collected trajectories:200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 14.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 240, Size of MDP:42236, Length of Train Buffer:999, Eval Reward:199.8\t####################\n",
      "Average Reward of collected trajectories:200.0\n",
      "Average Reward of collected trajectories:197.2\n",
      "Average Reward of collected trajectories:200.0\n",
      "Average Reward of collected trajectories:197.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 15.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 260, Size of MDP:46225, Length of Train Buffer:988, Eval Reward:198.2\t####################\n",
      "Average Reward of collected trajectories:200.0\n",
      "Average Reward of collected trajectories:200.0\n",
      "Average Reward of collected trajectories:200.0\n",
      "Average Reward of collected trajectories:188.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 15.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 280, Size of MDP:50183, Length of Train Buffer:941, Eval Reward:195.88\t####################\n",
      "Average Reward of collected trajectories:193.2\n",
      "Average Reward of collected trajectories:200.0\n",
      "Average Reward of collected trajectories:200.0\n",
      "Average Reward of collected trajectories:200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 16.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 300, Size of MDP:54165, Length of Train Buffer:999, Eval Reward:200.0\t####################\n",
      "Average Reward of collected trajectories:27.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 40.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 5, Size of MDP:140, Length of Train Buffer:137, Eval Reward:80.7\t####################\n",
      "Average Reward of collected trajectories:56.0\n",
      "Average Reward of collected trajectories:132.0\n",
      "Average Reward of collected trajectories:136.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 20.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 20, Size of MDP:1766, Length of Train Buffer:683, Eval Reward:159.4\t####################\n",
      "Average Reward of collected trajectories:131.0\n",
      "Average Reward of collected trajectories:149.2\n",
      "Average Reward of collected trajectories:155.0\n",
      "Average Reward of collected trajectories:131.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 19.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 40, Size of MDP:4602, Length of Train Buffer:655, Eval Reward:172.52\t####################\n",
      "Average Reward of collected trajectories:145.8\n",
      "Average Reward of collected trajectories:157.2\n",
      "Average Reward of collected trajectories:155.4\n",
      "Average Reward of collected trajectories:159.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 15.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 60, Size of MDP:7694, Length of Train Buffer:795, Eval Reward:190.62\t####################\n",
      "Average Reward of collected trajectories:121.2\n",
      "Average Reward of collected trajectories:150.0\n",
      "Average Reward of collected trajectories:190.2\n",
      "Average Reward of collected trajectories:176.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 15.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 80, Size of MDP:10889, Length of Train Buffer:882, Eval Reward:192.5\t####################\n",
      "Average Reward of collected trajectories:200.0\n",
      "Average Reward of collected trajectories:164.2\n",
      "Average Reward of collected trajectories:198.0\n",
      "Average Reward of collected trajectories:186.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 15.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 100, Size of MDP:14644, Length of Train Buffer:933, Eval Reward:192.44\t####################\n",
      "Average Reward of collected trajectories:184.6\n",
      "Average Reward of collected trajectories:195.4\n",
      "Average Reward of collected trajectories:161.2\n",
      "Average Reward of collected trajectories:179.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 15.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 120, Size of MDP:18259, Length of Train Buffer:896, Eval Reward:194.62\t####################\n",
      "Average Reward of collected trajectories:151.8\n",
      "Average Reward of collected trajectories:185.4\n",
      "Average Reward of collected trajectories:196.6\n",
      "Average Reward of collected trajectories:189.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 15.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 140, Size of MDP:21886, Length of Train Buffer:947, Eval Reward:194.14\t####################\n",
      "Average Reward of collected trajectories:198.4\n",
      "Average Reward of collected trajectories:162.4\n",
      "Average Reward of collected trajectories:140.4\n",
      "Average Reward of collected trajectories:177.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 15.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 160, Size of MDP:25288, Length of Train Buffer:888, Eval Reward:193.38\t####################\n",
      "Average Reward of collected trajectories:193.0\n",
      "Average Reward of collected trajectories:195.2\n",
      "Average Reward of collected trajectories:165.2\n",
      "Average Reward of collected trajectories:197.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 15.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 180, Size of MDP:29055, Length of Train Buffer:987, Eval Reward:191.42\t####################\n",
      "Average Reward of collected trajectories:181.2\n",
      "Average Reward of collected trajectories:194.0\n",
      "Average Reward of collected trajectories:200.0\n",
      "Average Reward of collected trajectories:199.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 15.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 200, Size of MDP:32941, Length of Train Buffer:998, Eval Reward:195.62\t####################\n",
      "Average Reward of collected trajectories:178.2\n",
      "Average Reward of collected trajectories:106.6\n",
      "Average Reward of collected trajectories:200.0\n",
      "Average Reward of collected trajectories:194.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 15.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 220, Size of MDP:36346, Length of Train Buffer:972, Eval Reward:193.02\t####################\n",
      "Average Reward of collected trajectories:200.0\n",
      "Average Reward of collected trajectories:189.4\n",
      "Average Reward of collected trajectories:200.0\n",
      "Average Reward of collected trajectories:188.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 14.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 240, Size of MDP:40251, Length of Train Buffer:943, Eval Reward:197.88\t####################\n",
      "Average Reward of collected trajectories:187.2\n",
      "Average Reward of collected trajectories:190.2\n",
      "Average Reward of collected trajectories:178.6\n",
      "Average Reward of collected trajectories:191.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 14.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 260, Size of MDP:44001, Length of Train Buffer:956, Eval Reward:197.12\t####################\n",
      "Average Reward of collected trajectories:200.0\n",
      "Average Reward of collected trajectories:158.4\n",
      "Average Reward of collected trajectories:197.2\n",
      "Average Reward of collected trajectories:181.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 12.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 280, Size of MDP:47698, Length of Train Buffer:906, Eval Reward:197.64\t####################\n",
      "Average Reward of collected trajectories:187.0\n",
      "Average Reward of collected trajectories:200.0\n",
      "Average Reward of collected trajectories:196.8\n",
      "Average Reward of collected trajectories:173.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 15.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\t Episode: 300, Size of MDP:51496, Length of Train Buffer:866, Eval Reward:197.24\t####################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_reward_data = pd.DataFrame.from_dict({\"Epiodes\":[],\"Performance\":[]})\n",
    "\n",
    "for seed in [0,2,4]:\n",
    "    myAgent =  cpy(newAgent)\n",
    "    print(\"\\n\\n\\n\", \"#\"*30 , f\"\\tSeed {seed} Run\\t\",\"#\"*30 , \"\\n\" )\n",
    "    for i in range(1,61):\n",
    "        train_buffer, info = gather_data_in_buffer(cpy(empty_buffer), env,policy = myAgent.policies[\"eps_optimal\"] if i>1 else myAgent.policies[\"random\"], episode_count=5, frame_count=1000)\n",
    "        myAgent.build_mdp(train_buffer, verbose= False)\n",
    "        \n",
    "        if i%4==0 or i == 1:\n",
    "            eval_reward = evaluate_on_env(env,myAgent.policies[\"optimal\"], eps_count=10,progress_bar=True)[0]\n",
    "            print(\"#\"*20 + f\"\\t Episode: {i*5}, Size of MDP:{np.sum(myAgent.mdp_T.filled_mask)}, Appended transitions:{len(train_buffer)}, Eval Reward:{eval_reward}\\t\" + \"#\"*20)\n",
    "            eval_reward_data.loc[len(eval_reward_data)] = (i*5,eval_reward)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 1.0, 'CartPole Performance , Averaged over 3 Seeds \\n solved every 5 episodes, exploration: eps_optimal policy')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.lineplot(data=eval_reward_data, x = \"Epiodes\", y = \"Performance\")\n",
    "ax.set(title='CartPole Performance , Averaged over 3 Seeds \\n solved every 5 episodes, exploration: eps_optimal policy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
