{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# import plotly.graph_objects as go\n",
    "from tqdm import tqdm\n",
    "from gym import envs\n",
    "import argparse\n",
    "import numpy as np\n",
    "from bigmdp.data.buffer import StandardBuffer,ReplayBuffer, gather_data_in_buffer, get_iter_indexes\n",
    "from bigmdp.mdp.MDP_GPU import FullMDP\n",
    "from bigmdp.utils.utils_eval import evaluate_on_env\n",
    "from bigmdp.mdp.agent import SimpleAgent\n",
    "from copy import deepcopy as cpy\n",
    "from os import path\n",
    "from arg_def import * \n",
    "import gym\n",
    "from sklearn.neighbors import KDTree\n",
    "from IPython import display\n",
    "import torch\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################    envArgs    ##################################################\n",
      "env_name                       : CartPole-v0                    seed                           : 4444\n",
      "###################################################################################################################\n",
      "##################################################    mdpBuildArgs    ##################################################\n",
      "unknown_transition_reward      : -1000                          rmax_reward                    : 10000\n",
      "balanced_exploration           : 0                              rmax_threshold                 : 2\n",
      "MAX_S_COUNT                    : 15000                          def_device                     : GPU\n",
      "fill_with                      : 0Q_src-KNN                     mdp_build_k                    : 5\n",
      "knn_delta                      : 1e-08                          penalty_type                   : linear\n",
      "penalty_beta                   : 1                              filter_with_abstraction        : 0\n",
      "normalize_by_distance          : True                          \n",
      "########################################################################################################################\n",
      "##################################################    mdpSolveArgs    ##################################################\n",
      "gamma                          : 0.99                           slip_probability               : 0.1\n",
      "target_vi_error                : 0.001                          bellman_backup_every           : 100\n",
      "n_backups                      : 10                             policy_k                       : [11]\n",
      "########################################################################################################################\n",
      "##################################################    evalArgs    ##################################################\n",
      "eval_episode_count             : 249                            soft_q                         : False\n",
      "smooth_with_seen               : False                          policy_k                       : [11]\n",
      "####################################################################################################################\n"
     ]
    }
   ],
   "source": [
    "parser, ArgumentDict = get_argument_parser()\n",
    "options = \"--env_name CartPole-v0 --MAX_S_COUNT 15000 --MAX_NS_COUNT 5 --mdp_build_k 5 --policy_k 11 --normalize_by_distance\"\n",
    "args = parser.parse_args(options.split(\" \"))\n",
    "\n",
    "for title, arg_names in ArgumentDict.items():\n",
    "    print_args(args, to_show_args=arg_names, title = title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_wrappers import *\n",
    "env = gym.make(args.env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_buffer = ReplayBuffer(state_dim = env.observation_space.shape[0],\n",
    "                           is_atari= False, \n",
    "                           atari_preprocessing= None, \n",
    "                           batch_size=32, \n",
    "                           buffer_size=20000,\n",
    "                           device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_buffer, info = gather_data_in_buffer(train_buffer, env,policy = lambda s:np.random.randint(2), episode_count=99999, frame_count=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyNet():\n",
    "    def __init__(self, sim, add_noise=False):\n",
    "        self.simulator = sim\n",
    "\n",
    "    def encode_single(self, o):\n",
    "        return tuple(o)\n",
    "\n",
    "    def encode_batch(self, o_batch):\n",
    "        return [tuple(o) for o in o_batch]\n",
    "\n",
    "    def predict_single_transition(self, o, a):\n",
    "        assert False, \"Not Implemented Error\"\n",
    "\n",
    "    def predict_batch_transition(self, o_batch, a_batch):\n",
    "        assert False, \"Not Implemented Error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 804.33it/s]\n",
      " 14%|█▍        | 1424/10012 [00:00<00:00, 14237.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 (Parse Transitions):  Running\n",
      "Step 1 [Parse Transitions]:  Complete,  Time Elapsed: 0.054155588150024414\n",
      "\n",
      "\n",
      "Step 2 [Seed Seen Transitions + Unknown (s,a) pairs]:  Running\n",
      "Len of to commit transitions 10012\n",
      "ABstraction Faldg False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10012/10012 [00:00<00:00, 16558.47it/s]\n",
      "  2%|▏         | 395/20026 [00:00<00:04, 3946.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of to commit sa pairs 20026\n",
      "Step 2 (Commit Seen Transitions):  Complete,  Time Elapsed: 0.6531634330749512 \n",
      "\n",
      "\n",
      "Step 3 [Commit all Transitions]:  Running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20026/20026 [00:04<00:00, 4020.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3 (Commit UnSeen Transitions):  Complete,  Time Elapsed: 4.983672380447388\n",
      "Step 4 [Solve MDP]:  Running\n",
      "Elapsed Time:0s, VI Error:0.08272552, #Backups: 250\n",
      "Elapsed Time:1s, VI Error:0.00673676, #Backups: 500\n",
      "Elapsed Time:1s, VI Error:0.00058746, #Backups: 750\n",
      "Time takedn to solve 1.9754598140716553\n",
      "% of missing trans 0.0\n",
      "Step 4 [Solve MDP]:  Complete,  Time Elapsed: 3.0332117080688477\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empty_MDP = FullMDP(A= list(range(env.action_space.n)),\n",
    "                    ur=args.unknown_transition_reward,\n",
    "                    vi_params={\"gamma\":  args.gamma,\n",
    "                               \"slip_prob\": args.slip_probability,\n",
    "                               \"rmax_reward\": args.rmax_reward,\n",
    "                               \"rmax_thres\": args.rmax_threshold,\n",
    "                               \"balanced_explr\": args.balanced_exploration,\n",
    "                              \"rmin\":-1000},\n",
    "                    knn_delta=args.knn_delta,\n",
    "                    MAX_S_COUNT=args.MAX_S_COUNT,\n",
    "                    MAX_NS_COUNT=args.MAX_NS_COUNT,\n",
    "                    default_mode=args.def_device)\n",
    "\n",
    "myAgent =  SimpleAgent(mdp_T= empty_MDP, net = DummyNet(None), fill_with = args.fill_with,\n",
    "                       mdp_build_k = args.mdp_build_k, plcy_k = args.policy_k[0],  \n",
    "                       kNN_on_sa = args.smooth_with_seen, soft_at_plcy = args.soft_q, \n",
    "                       normalize_by_distance= args.normalize_by_distance,\n",
    "                       penalty_type=args.penalty_type, penalty_beta = args.penalty_beta,abstraction_flag=False)\n",
    "\n",
    "myAgent.build_mdp(train_buffer, verbose= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [00:00<00:03, 13.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy Parmeters - policy_k:11, Weighted Neighbors:True, kNN_on_sa:False, soft:False,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 14.90it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 1412.39it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 16.63it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 15.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'optimal': 200.0, 'random': 20.16, 'eps_optimal': 200.0, 'safe': 200.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Policy Parmeters - policy_k:{myAgent.plcy_k}, Weighted Neighbors:{myAgent.norm_by_dist}, kNN_on_sa:{myAgent.kNN_on_sa}, soft:{myAgent.soft_at_plcy},\")\n",
    "sum_reward_running = {policy_name:evaluate_on_env(env,  \n",
    "                                                  policy, \n",
    "                                                  eps_count=50,progress_bar=True)[0]\n",
    "                      for policy_name,policy in myAgent.policies.items()}\n",
    "print(sum_reward_running)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
