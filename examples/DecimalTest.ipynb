{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Environment  Loaded\n",
      "20000 20000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 15:41:26,250:mylogger:Average Reward of collected trajectories:21.907\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0228 15:41:26.250660 140416558835520 dataset.py:292] Average Reward of collected trajectories:21.907\n",
      "2020-02-28 15:41:26,353:mylogger:Average Reward of collected trajectories:23.585\n",
      "I0228 15:41:26.353203 140416558835520 dataset.py:292] Average Reward of collected trajectories:23.585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward of collected trajectories:21.907\n",
      "Average Reward of collected trajectories:23.585\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import argparse\n",
    "from copy import deepcopy as cpy\n",
    "\n",
    "# from async_vi.MDP import *\n",
    "import numpy as np\n",
    "from bigmdp.data.dataset import SimpleReplayBuffer, PrioritizedReplayBuffer\n",
    "from bigmdp.data.env_gym import SimpleNormalizeEnv\n",
    "from bigmdp.mdp.MDP_GPU import FullMDP\n",
    "from bigmdp.utils.image_wrappers import *\n",
    "from bigmdp.utils.tmp_vi_helper import *\n",
    "from bigmdp.utils.utils_directory import *\n",
    "from bigmdp.utils.utils_log import *\n",
    "from hyper_params import HYPERPARAMS\n",
    "\n",
    "# Get all Arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--bottle_neck_size\", help=\"size\", type=int, default=32)\n",
    "parser.add_argument(\"--discrete_bn\", help=\"size\", type=int, default=0)\n",
    "parser.add_argument(\"--multiplyer\", help=\"multiplyer of feature space\", type=int, default=10)\n",
    "parser.add_argument(\"--env\", help=\"environment name\", type=str, default=\"CartPole\")\n",
    "parser.add_argument(\"--name\", help=\"Experiment name\", type=str, default=\"CartPoleR1\")\n",
    "parser.add_argument(\"--load\", help=\"Load the previous MDP ?\", type=int, default=0)\n",
    "parser.add_argument(\"--symbolic\", help=\"Use Symbolic env if 1 else use image based env\", type=int, default=1)\n",
    "parser.add_argument(\"--steps_to_train\", help=\"Number of steps to train the whole pipeline\", type=int, default=0)\n",
    "parser.add_argument(\"--rmax\", help=\"Use rmax exploration?\", type=int, default=0)\n",
    "parser.add_argument(\"--strict_rmax\", help=\"Use rmax exploration and rmax exploration alone?\", type=int, default=0)\n",
    "parser.add_argument(\"--video_every\", help=\"get a rollout video every\", type=int, default=999999999)\n",
    "parser.add_argument(\"--backup_every\", help=\"do a bellman backup every k frames\", type=int, default=10)\n",
    "parser.add_argument(\"--device\", help=\"do backups on ?\", type=str, default=\"GPU\")\n",
    "parser.add_argument(\"--save_transitions\", help=\"do backups on ?\", type=int, default=0)\n",
    "parser.add_argument(\"--shaped_reward\", help=\"Use shaped rewards?\", type=int, default=0)\n",
    "parser.add_argument(\"--load_time_string\", help=\"timestep string\", type=str, default=\"default_time\")\n",
    "parser.add_argument(\"--use_priority_buffer\", help=\"Use priority buffer ?\", type=int, default=0)\n",
    "parser.add_argument(\"--render_every\", help=\"render a episode every kth episode\", type=int, default=0)\n",
    "parser.add_argument(\"--internal_count_override\", help=\"override internal count\", type=int, default=0)\n",
    "\n",
    "\n",
    "# args = parser.parse_args()\n",
    "args = parser.parse_args(\"--env CartPole --multiplyer 5 --rmax 0 --backup_every 100 --render_every 10000\".split(\" \"))\n",
    "\n",
    "run_params = \"_bn-\" + str(args.bottle_neck_size) + \\\n",
    "             \"_sym-\" + str(args.symbolic) + \\\n",
    "             \"_rmax-\" + str(bool(args.rmax)) + \\\n",
    "             \"_strict_rmax-\" + str(bool(args.strict_rmax)) + \\\n",
    "             \"_mult-\" + str(args.multiplyer) + \\\n",
    "             \"_bkp_f-\" + str(args.backup_every) + \\\n",
    "             \"_device-\" + str(args.device) + \\\n",
    "             \"_priority-\" + str(args.use_priority_buffer)\n",
    "\n",
    "base_file_path = \"./result_dump/{}/{}\".format(args.env, args.name + run_params)\n",
    "\n",
    "create_hierarchy(base_file_path)\n",
    "\n",
    "train_epochs = 20\n",
    "\n",
    "log_dirs_dict, loggers_dict = get_advanced_log_dir_and_logger(ROOT_FOLDER=\"Symbolic\" if args.symbolic else \"Image\",\n",
    "                                                              EXP_ID=args.env + \"-Dec\", #todo remove for general\n",
    "                                                              EXP_PARAMS=run_params,\n",
    "                                                              load_time_string=args.load_time_string,\n",
    "                                                              tb_log_keys=[\"tb_train_logger\", \"tb_valid_logger\"])\n",
    "\n",
    "if args.symbolic:\n",
    "    params = HYPERPARAMS[args.env + \"-sym\"]\n",
    "    if os.path.exists(\"./\" + str(args.env) + \"_env.pk\"):\n",
    "        print(\" Environment  Loaded\")\n",
    "        env = torch.load(\"./\" + str(args.env) + \"_env.pk\")\n",
    "    else:\n",
    "        env = SimpleNormalizeEnv(params[\"env_name\"], max_episode_length=params[\"max_episode_length\"])\n",
    "        torch.save(env, \"./\" + str(args.env) + \"_env.pk\")\n",
    "else:\n",
    "    print(\"Not Implemented Yet\")  # Todo\n",
    "    params = HYPERPARAMS[args.env + \"-img\"]\n",
    "    assert False\n",
    "\n",
    "test_env = cpy(env)\n",
    "\n",
    "\n",
    "K_s, K_i = params[\"replay_initial\"], args.internal_count_override if args.internal_count_override else params[\n",
    "    'internal_step_count_per_policy']\n",
    "print(K_i, K_s)\n",
    "\n",
    "if args.load:\n",
    "    mdp = torch.load(base_file_path + \"mdp_class.pth\")\n",
    "else:\n",
    "    mdp = FullMDP(A=env.get_list_of_actions(),\n",
    "                  ur=params[\"unknown_transition_reward\"],\n",
    "                  vi_params={\"gamma\": params[\"gamma\"],\n",
    "                             \"slip_prob\": params[\"slip_probability\"],\n",
    "                             \"rmax_reward\": params[\"rmax_reward\"],\n",
    "                             \"rmax_thres\": 2,\n",
    "                             \"balanced_explr\": True,\n",
    "                             \"rmin\": params[\"rmin\"]},\n",
    "                  policy_params={\"unhash_array_len\": env._env.observation_space.shape[0]},\n",
    "                  MAX_S_COUNT=int(1e6),\n",
    "                  weight_transitions=False,\n",
    "                  default_mode = args.device)\n",
    "\n",
    "all_rewards = []\n",
    "eval_rewards, safe_eval_rewards = [], []\n",
    "policy_fetch_time = []\n",
    "bellman_backup_time = [9999]\n",
    "train_buffer = PrioritizedReplayBuffer(int(5e5)) if args.use_priority_buffer else SimpleReplayBuffer(int(5e5))\n",
    "valid_buffer = PrioritizedReplayBuffer(int(1e5)) if args.use_priority_buffer else SimpleReplayBuffer(int(5e5))\n",
    "\n",
    "eps_tracker = EpsilonTracker(params)\n",
    "\n",
    "frame_count = 0\n",
    "warmup_eps = 10\n",
    "eval_reward = 0\n",
    "\n",
    "omit_list = [\"end_state\", \"unknown_state\"]\n",
    "\n",
    "from bigmdp.data.dataset import gather_data_in_buffer\n",
    "from learnt_mdp_helper import *\n",
    "\n",
    "# Collect random Dataset # till replay initial\\\n",
    "random_policy = lambda s: env.sample_random_action()\n",
    "train_buffer, info = gather_data_in_buffer(train_buffer, env, episodes=9999, render=False, policy=random_policy,\n",
    "                                           frame_count=K_s, pad_attribute_fxn={\"qval\": lambda s: 0})\n",
    "valid_buffer, info = gather_data_in_buffer(valid_buffer, env, episodes=9999, render=False, policy=random_policy,\n",
    "                                           frame_count=int(K_s / 5), pad_attribute_fxn={\"qval\": lambda s: 0})\n",
    "\n",
    "# recon_loss_wts = {h:0 for h in training_net.head_ids}\n",
    "# recon_loss_wts[\"recon\"] = 1\n",
    "# training_net.default_loss_wts  = recon_loss_wts\n",
    "# training_net.fit(train_buffer,valid_buffer, epochs=50)\n",
    "frame_count = 0\n",
    "print(frame_count)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "args.model_update_every = 500\n",
    "\n",
    "outer_loop_frame_count = len(train_buffer)\n",
    "\n",
    "    # torch.save((train_buffer.buffer, mdp, net.state_dict()), log_dirs_dict[\"py_log_dir\"] + \"/checkpoint\" + \".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params[\"evaluate_every\"] = 5000\n",
    "params[\"outer_iteration_count\"] = 1\n",
    "params[\"bellman_backup_every\"] = 100\n",
    "params[\"n_backups\"] = 10\n",
    "K_i = int(2e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_2_disc_fxn(s):\n",
    "    if len(s)==1:\n",
    "        return s[0] * args.multiplyer\n",
    "    else:\n",
    "        return [s_ * args.multiplyer for s_ in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:05<00:00, 15.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of MDP, 496\n",
      "Time takedn to solve 2.43491792678833\n"
     ]
    }
   ],
   "source": [
    "\n",
    "outer_count = 0 \n",
    "# Update the buffer with new values\n",
    "# For Disc: Skipped\n",
    "\n",
    "# Train your Network\n",
    "# For Disc: Skipped\n",
    "\n",
    "#Make MDP\n",
    "mdp_T = FullMDP(A=env.get_list_of_actions(),\n",
    "              ur=params[\"unknown_transition_reward\"],\n",
    "              vi_params={\"gamma\": params[\"gamma\"],\n",
    "                         \"slip_prob\": params[\"slip_probability\"],\n",
    "                         \"rmax_reward\": params[\"rmax_reward\"],\n",
    "                         \"rmax_thres\": 2,\n",
    "                         \"balanced_explr\": True,\n",
    "                         \"rmin\": params[\"rmin\"]},\n",
    "              policy_params={\"unhash_array_len\": env._env.observation_space.shape[0]},\n",
    "              MAX_S_COUNT=int(1e6),\n",
    "              weight_transitions=True,\n",
    "              default_mode=\"GPU\")\n",
    "\n",
    "# Populate your MDP\n",
    "mdp_T = populate_model_from_buffer(mdp_T, train_buffer, img_2_disc_fxn)\n",
    "print(\"Size of MDP,\", len(mdp_T.tD))\n",
    "\n",
    "# Solve Your MDP\n",
    "mdp_T.solve(eps=1, mode=args.device)\n",
    "\n",
    "# for mdp_name, M in {\"Tabular\": mdp_T, \"Tabular_Insertion\": mdp_TI}.items():\n",
    "\n",
    "opt_policy = lambda s: mdp_T.get_opt_action(hAsh(img_2_disc_fxn([s]).tolist()), mode = args.device)\n",
    "safe_policy = lambda s: mdp_T.get_safe_action(hAsh(img_2_disc_fxn([s]).tolist()), mode = args.device)\n",
    "explr_policy = lambda s: mdp_T.get_explr_action(hAsh(img_2_disc_fxn([s]).tolist()), mode = args.device)\n",
    "random_policy = lambda s: env.sample_random_action()\n",
    "eps_opt_policy = get_eps_policy(opt_policy, random_policy, epsilon=0.2)\n",
    "\n",
    "if args.strict_rmax:\n",
    "    explore_policies = {\"explr_policy\": explr_policy}\n",
    "elif args.rmax:\n",
    "    explore_policies = {\"explr_policy\": explr_policy, \"opt_policy\": opt_policy}\n",
    "else:\n",
    "    explore_policies = {\"opt_policy\": opt_policy, \"eps_opt_policy\":eps_opt_policy}\n",
    "\n",
    "s = env.reset()\n",
    "running_reward = 0\n",
    "inner_loop_frame_count = 0\n",
    "eps_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.render_every = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5007/100000000 [00:27<3085:17:30,  9.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "78.84          | 657         | 343/1314              | 0.261      | 0.39984130859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10007/100000000 [00:55<2869:20:35,  9.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "116.4          | 854         | 495/1708              | 0.2898     | 0.593780517578125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 15006/100000000 [01:22<3054:40:43,  9.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "176.52         | 974         | 571/1948              | 0.2931     | 0.554718017578125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 20005/100000000 [01:51<3336:50:19,  8.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "122.5          | 1092        | 645/2184              | 0.2953     | 1.31256103515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 25000/100000000 [02:20<4457:39:47,  6.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "131.58         | 1162        | 681/2324              | 0.293      | 1.6876220703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 30000/100000000 [02:50<4529:51:08,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "88.3           | 1277        | 755/2554              | 0.2956     | 32.89703369140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 35009/100000000 [03:17<2716:55:11, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "163.58         | 1325        | 765/2650              | 0.2887     | 12.09625244140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 40008/100000000 [03:48<3693:59:35,  7.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "250.24         | 1377        | 798/2754              | 0.2898     | 4.44677734375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 45008/100000000 [04:17<3323:52:00,  8.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "283.62         | 1450        | 847/2900              | 0.2921     | 1.63446044921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 50006/100000000 [04:45<2958:56:29,  9.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "148.42         | 1513        | 886/3026              | 0.2928     | 11.619873046875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 55007/100000000 [05:14<3106:44:40,  8.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "232.22         | 1574        | 918/3148              | 0.2916     | 3.362060546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 60007/100000000 [05:44<3599:48:12,  7.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "236.82         | 1642        | 959/3284              | 0.292      | 1.23675537109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 65006/100000000 [06:12<3115:49:35,  8.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "223.2          | 1738        | 1024/3476             | 0.2946     | 0.57220458984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 70005/100000000 [06:41<3152:14:46,  8.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "287.1          | 1825        | 1082/3650             | 0.2964     | 1.3369140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 75000/100000000 [07:10<4473:34:34,  6.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "181.58         | 1853        | 1091/3706             | 0.2944     | 0.7327880859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 80005/100000000 [07:39<3211:34:37,  8.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "267.12         | 1904        | 1114/3808             | 0.2925     | 0.59814453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 85000/100000000 [08:13<5974:47:23,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "307.78         | 1943        | 1132/3886             | 0.2913     | 0.48150634765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 90007/100000000 [08:41<3077:49:55,  9.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "187.5          | 1990        | 1157/3980             | 0.2907     | 0.57220458984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 95000/100000000 [09:10<4437:16:50,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "262.7          | 2064        | 1194/4128             | 0.2892     | 149.3851318359375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 100004/100000000 [09:38<3502:05:04,  7.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "194.8          | 2115        | 1215/4230             | 0.2872     | 8.61968994140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 105007/100000000 [10:07<3243:09:34,  8.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "250.32         | 2184        | 1260/4368             | 0.2885     | 3.169189453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 110006/100000000 [10:37<3522:08:21,  7.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "189.74         | 2251        | 1306/4502             | 0.2901     | 1.16644287109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 115006/100000000 [11:06<3051:35:35,  9.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "238.1          | 2318        | 1340/4636             | 0.289      | 4.2772216796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 120005/100000000 [11:35<3281:11:35,  8.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "251.3          | 2335        | 1327/4670             | 0.2842     | 1.5733642578125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 125006/100000000 [12:04<3218:23:55,  8.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "219.08         | 2372        | 1348/4744             | 0.2841     | 0.579345703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 130007/100000000 [12:32<3113:15:47,  8.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "197.0          | 2481        | 1420/4962             | 0.2862     | 9.7523193359375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 135006/100000000 [13:01<3297:15:08,  8.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "271.0          | 2526        | 1439/5052             | 0.2848     | 38.03369140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 140006/100000000 [13:29<3018:05:05,  9.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "236.86         | 2597        | 1487/5194             | 0.2863     | 13.984130859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 145006/100000000 [13:59<3628:56:15,  7.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "323.12         | 2647        | 1510/5294             | 0.2852     | 0.48419189453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 150006/100000000 [14:27<3243:20:24,  8.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "316.58         | 2683        | 1515/5366             | 0.2823     | 36.23162841796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 155004/100000000 [14:56<3158:39:54,  8.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "251.4          | 2716        | 1533/5432             | 0.2822     | 0.45684814453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 160006/100000000 [15:24<2997:58:23,  9.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "260.76         | 2750        | 1542/5500             | 0.2804     | 1.947967529296875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 165006/100000000 [15:52<3238:08:46,  8.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "177.1          | 2802        | 1567/5604             | 0.2796     | 0.517333984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 170000/100000000 [16:22<4643:18:21,  5.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "246.3          | 2869        | 1613/5738             | 0.2811     | 17.24200439453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 175010/100000000 [16:50<2624:40:45, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "235.64         | 2911        | 1631/5822             | 0.2801     | 0.8953857421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 180007/100000000 [17:17<2850:58:37,  9.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "242.12         | 2948        | 1647/5896             | 0.2793     | 0.492462158203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 185006/100000000 [17:46<3227:05:22,  8.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "247.54         | 3013        | 1693/6026             | 0.2809     | 0.54974365234375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 190007/100000000 [18:14<2893:17:44,  9.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "289.32         | 3075        | 1732/6150             | 0.2816     | 0.580841064453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 195006/100000000 [18:45<3932:21:23,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "297.72         | 3106        | 1744/6212             | 0.2807     | 0.56707763671875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 200008/100000000 [19:15<3215:16:01,  8.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "290.18         | 3149        | 1767/6298             | 0.2806     | 0.59033203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 205005/100000000 [19:43<2967:34:21,  9.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "242.22         | 3192        | 1793/6384             | 0.2809     | 5.61187744140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 210006/100000000 [20:11<2935:45:33,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "303.96         | 3219        | 1795/6438             | 0.2788     | 2.0633544921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 215004/100000000 [20:38<3177:41:49,  8.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "261.76         | 3253        | 1814/6506             | 0.2788     | 0.75860595703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 220006/100000000 [21:06<3073:18:04,  9.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "243.6          | 3282        | 1825/6564             | 0.278      | 0.580963134765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 225006/100000000 [21:37<3905:19:36,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "327.1          | 3326        | 1847/6652             | 0.2777     | 0.441162109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 230003/100000000 [22:06<3291:10:42,  8.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "286.84         | 3379        | 1880/6758             | 0.2782     | 1.354705810546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 235005/100000000 [22:35<3363:10:51,  8.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "290.56         | 3428        | 1907/6856             | 0.2782     | 14.98516845703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 240006/100000000 [23:02<2851:12:37,  9.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "297.86         | 3462        | 1917/6924             | 0.2769     | 1.640380859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 245005/100000000 [23:30<3029:58:03,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "277.76         | 3477        | 1918/6954             | 0.2758     | 0.60479736328125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 250005/100000000 [24:00<3141:46:39,  8.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "322.48         | 3507        | 1929/7014             | 0.275      | 0.517852783203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 255007/100000000 [24:28<3039:03:38,  9.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "334.88         | 3546        | 1951/7092             | 0.2751     | 0.9178466796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 260006/100000000 [24:56<3022:08:58,  9.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "299.36         | 3578        | 1959/7156             | 0.2738     | 0.940338134765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 265006/100000000 [25:28<3945:51:20,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward | MDP #States | #MissingTrans/ #Trans | Missing %. | VI Error..\n",
      "294.58         | 3611        | 1974/7222             | 0.2733     | 1.4024658203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 267577/100000000 [25:38<99:31:30, 278.36it/s] "
     ]
    }
   ],
   "source": [
    "\n",
    "for i in tqdm(range(int(1e8))):\n",
    "    inner_loop_frame_count += 1\n",
    "    outer_loop_frame_count += 1\n",
    "\n",
    "    if args.render_every and eps_count % args.render_every == 0:\n",
    "        env.render()\n",
    "\n",
    "    if outer_loop_frame_count % params['bellman_backup_every'] == 0:\n",
    "        st = time.time()\n",
    "        mdp_T.do_optimal_backup(mode=args.device, n_backups=params[\"n_backups\"])\n",
    "        if args.rmax:\n",
    "            mdp_T.do_explr_backup(mode=args.device, n_backups=params[\"n_backups\"])\n",
    "        bellman_backup_time.append(time.time() - st)\n",
    "\n",
    "    policy_name, policy = \"a\", eps_opt_policy # list(explore_policies.items())[eps_count%len(explore_policies)]\n",
    "    a = policy(s)\n",
    "\n",
    "    ns, r, d, i = env.step(a)\n",
    "    _d = False if d and i[\"max_episode_length_exceeded\"] == True else d\n",
    "    running_reward += r\n",
    "\n",
    "    # add to buffer\n",
    "    # Not necessary for Decimal Discretization bur sure\n",
    "    exp = [s.tolist(), [a], ns.tolist(), [r], [_d]]\n",
    "    train_buffer.add(exp, padded_info={\"qval\": 0})\n",
    "    if np.random.randint(20) < 2:\n",
    "        valid_buffer.add(exp, padded_info={\"qval\": 0})\n",
    "\n",
    "    # Update MDP\n",
    "    s_d, ns_d = img_2_disc_fxn([s]), img_2_disc_fxn([ns])\n",
    "    hs_d, hns_d = hAsh(s_d.tolist()), hAsh(ns_d.tolist())\n",
    "    mdp_T.consume_transition([hs_d, int(a), hns_d, float(r), int(_d)])\n",
    "#     mdp_T.consume_transition((hAsh(hs.tolist()), int(a), hAsh(hns.tolist()), float(r), int(_d)))\n",
    "\n",
    "    # prep for next loop\n",
    "    s = ns\n",
    "\n",
    "    # Housekeeping to omit while true loop\n",
    "    if d:\n",
    "        s = env.reset()\n",
    "        running_reward = 0\n",
    "        eps_count += 1\n",
    "\n",
    "    if inner_loop_frame_count % params['evaluate_every'] == 0:\n",
    "        mdp_T.do_optimal_backup(mode=\"GPU\", n_backups=500)\n",
    "        n_steps = outer_count * K_i + inner_loop_frame_count\n",
    "        eval_reward = evaluate_on_env(test_env, opt_policy, eps_count=50, render=False)[0]\n",
    "        \n",
    "        col_header = [\"Average Reward\",\"MDP #States\", \"#MissingTrans/ #Trans\",\"Missing %\", \"VI Error\"] \n",
    "        meta_data = [10]*len(col_header) # max len of the data in the table to be printed (per column)\n",
    "        print(' | '.join([s.ljust(max(meta_data[i], len(s)), '.') for i, s in enumerate(col_header)]))\n",
    "        col_data = [eval_reward, \n",
    "                    len(mdp_T.tD),  \n",
    "                    str(mdp_T.missing_state_action_count)+\"/\"+str(len(mdp_T.tD)*len(mdp_T.A)),\n",
    "                    round(mdp_T.missing_state_action_count/mdp_T.total_state_action_count,4 ),\n",
    "                    mdp_T.curr_vi_error       ]\n",
    "        print(' | '.join([str(s).ljust(max(meta_data[i], len(col_header[i])),  \" \") for i, s in enumerate(col_data)]))\n",
    "        \n",
    "        loggers_dict[\"tb_train_logger\"].add_scalar(\"Optimal Avg Reward\", n_steps)\n",
    "        loggers_dict[\"tb_train_logger\"].add_scalar(\"State Count\", float(len(mdp_T.tD)), outer_loop_frame_count)\n",
    "        loggers_dict[\"tb_train_logger\"].add_scalar('Mising Transition Count', mdp.missing_state_action_count, outer_loop_frame_count)\n",
    "        loggers_dict[\"tb_train_logger\"].add_scalar(\"Opt VI Error\",mdp_T.curr_vi_error, outer_loop_frame_count)\n",
    "        loggers_dict[\"tb_train_logger\"].add_scalar(\"Safe VI Error\",mdp_T.s_curr_vi_error, outer_loop_frame_count)\n",
    "\n",
    "    ####################################################\n",
    "\n",
    "    # Not necessary for Decimal Experiments\n",
    "    # if outer_loop_frame_count % args.checkpoint_every == 0:\n",
    "    #     training_net._save_to_cache()\n",
    "    #     torch.save((train_buffer.buffer, mdp, net.state_dict()),\n",
    "    #                log_dirs_dict[\"py_log_dir\"] + \"/checkpoint\" + \".pth\")\n",
    "\n",
    "# Not necessary for Decimal Experiments\n",
    "# training_net._save_to_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}